{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \"\"\"\n",
    "    Logistic regression model that takes in numpy arrays as input and returns numpy arrays as output.\n",
    "\n",
    "        random_state           : For setting the seed value.\n",
    "        epochs                 : No of iterations for gradient descent.\n",
    "        alpha                  : Learning rate.\n",
    "        regularization_term    : Used for regularization of weights.\n",
    "        decision_boundary      : Used for setting value of decision_boundary.\n",
    "        show_cost_iteration    : Set True if the user wants to see the iterations and corresponding cost.\n",
    "        cost_iteration_interval: Set an integer value if show_cost_iteration is true.\n",
    "\n",
    "    ### Attributes:\n",
    "        self.W             : Weight matrix.\n",
    "        self.b             : Bias value.\n",
    "        self.n_observations: No of observations in input data.\n",
    "        self.n_attributes  : No of attributes in input data.\n",
    "    \n",
    "    ### Methods: \n",
    "        fit(X, y) -> LogisticRegression:\n",
    "        Used for training the model.\n",
    "            X: Input feature matrix for training.\n",
    "            y: Input label vector for training.\n",
    "        predict(X) -> ArrayLike:\n",
    "        Used for predicting labels.\n",
    "            X: Input feature matrix for predicting labels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, random_state=0, epochs=1000, alpha=0.001, regularization_term=100, decision_boundary=0.5, show_cost_iteration=False, cost_iteration_interval=None):\n",
    "        np.random.seed(random_state)\n",
    "        self.epochs = epochs\n",
    "        self.alpha = alpha\n",
    "        self.regularization_term = regularization_term\n",
    "        self.decision_boundary = decision_boundary\n",
    "        self.show_cost_iteration = show_cost_iteration\n",
    "        self.cost_iteration_interval = cost_iteration_interval\n",
    "\n",
    "    def _sigmoid(self, Z):\n",
    "        return 1.0 / (1 + np.exp(-Z))\n",
    "\n",
    "    def _predict_y(self, X):\n",
    "        self.y_pred = np.matmul(X, self.W) + self.b\n",
    "        return self._sigmoid(self.y_pred)\n",
    "\n",
    "    def _cost_function(self, X, y):\n",
    "        # Calculating cost part.\n",
    "        left = np.dot(y.T, np.log(self._predict_y(X)))\n",
    "        right = np.dot((1-y).T, np.log(1-self._predict_y(X)))\n",
    "        cost_part = - (left + right)[0,0] /self.n_observations \n",
    "        \n",
    "        # Calculating regularization part.\n",
    "        regularization_part = np.sum(np.square(self.W), axis=0)[0] * (self.regularization_term/(2 * self.n_observations))\n",
    "\n",
    "        return cost_part + regularization_part\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.n_observations = X.shape[0]\n",
    "        # Finding no of features.\n",
    "        if (self.n_observations != X.size):\n",
    "            self.n_attributes = X.shape[1]\n",
    "        else:\n",
    "            self.n_attributes = 1\n",
    "\n",
    "        # Raise error if no of observations is not same for X and y.\n",
    "        if (self.n_observations != y.shape[0]):\n",
    "            raise ValueError(\"The number of observations aren't same for X and y.\")\n",
    "        \n",
    "        # Initialize values for weights and biases.\n",
    "        self.W = 0.1 * np.random.random((self.n_attributes, 1))\n",
    "        self.b = 0.1 * np.random.random()\n",
    "\n",
    "        # Converting input X and y to numpy arrays.\n",
    "        if (type(X) == pd.DataFrame or type(X) == pd.Series):\n",
    "            X = X.to_numpy()\n",
    "            if (self.n_attributes == 1):\n",
    "                X = X.reshape((self.n_observations,1))\n",
    "        if (type(y) == pd.Series):\n",
    "            y = y.to_numpy()\n",
    "        y = y.reshape((self.n_observations,1))\n",
    "\n",
    "        # Variable to store cost history.\n",
    "        self.cost_history = np.array([])\n",
    "\n",
    "        # Iterating for training.\n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            # Calculating the gradients of weights and bias.\n",
    "            diff_y = (self._predict_y(X) - y)\n",
    "            gradient_cost_part = np.matmul(X.T, diff_y) / self.n_observations \n",
    "            gradient_regularization_part = self.W * (self.regularization_term / self.n_observations)\n",
    "            gradient_W = gradient_cost_part + gradient_regularization_part\n",
    "            gradient_b = np.sum(diff_y, axis=0) / self.n_observations\n",
    "\n",
    "            # Updating weights and bias.\n",
    "            self.W = self.W - self.alpha * gradient_W\n",
    "            self.b = self.b - self.alpha * gradient_b\n",
    "            \n",
    "            # Saving cost function for auditing purposes.\n",
    "            cost = self._cost_function(X, y)\n",
    "            self.cost_history = np.append(self.cost_history, cost)\n",
    "\n",
    "            # Used for displaying iteration and corresponding cost.\n",
    "            if (self.show_cost_iteration and i%self.cost_iteration_interval == 0):\n",
    "                print(f\"Iteration: {str(i)}\\t Cost: {str(cost)}\")\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def _decision_boundary_calculation(self, predictions):\n",
    "        if (predictions > self.decision_boundary):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Check whether input X is in correct form or not.\n",
    "        if (X.shape[1] != self.n_attributes):\n",
    "            raise ValueError(\"Number of dimensions in test data is not same as trained data.\")\n",
    "        \n",
    "        # Convert to numpy array.\n",
    "        if (type(X) == pd.DataFrame or type(X) == pd.Series):\n",
    "            X = X.to_numpy()\n",
    "            if (self.n_attributes == 1):\n",
    "                X = X.reshape((self.n_observations,1))\n",
    "\n",
    "        # Predicting values.\n",
    "        decision_boundary = np.vectorize(self._decision_boundary_calculation)\n",
    "        return decision_boundary(self._predict_y(X)).flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=100, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = LogisticRegression(decision_boundary=0.5)\n",
    "model1.fit(X_train, y_train)\n",
    "predictions1 = model1.predict(X_test)\n",
    "predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972027972027972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, predictions1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51  2]\n",
      " [ 2 88]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, predictions1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972027972027972\n",
      "[[52  1]\n",
      " [ 3 87]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model2 = LogisticRegression()\n",
    "model2.fit(X_train, y_train)\n",
    "predictions2 = model2.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions2))\n",
    "print(confusion_matrix(y_test, predictions2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ef26ae64def31dd2af491ae64bd750868633f4444f69fd79cf74d36e9f525b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
